---
title: "TCGA-LIHC"
output:
  pdf_document: default
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---


```{r packages, message = FALSE}
library(tidyverse)
library(DESeq2)
library(rnaseqGene)
library(pheatmap)
library(ggalt)
library(fgsea)
library(biomaRt)
library(ggVennDiagram)
library(VennDiagram)
library(ggrepel)
library(jsonlite)
library(stringr)
library(fs)
library(dplyr)
library(GSVA)
library(ggpubr)
library(GSEABase)
library(CMScaller)

setwd("C:/Users/rohit/OneDrive - Loyola University Chicago/Zhang Lab/CRK HCC/")
```

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = 'C:/Users/rohit/OneDrive - Loyola University Chicago/Zhang Lab/CRK HCC/')
```

```{r functions}
run_gsea <- function(dds, condition1, condition2, gmt_path, output_gsea, output_deg) {
  suppressPackageStartupMessages({
    library(DESeq2)
    library(fgsea)
    library(BiocParallel)
    library(dplyr)
  })

  # Force serial execution to avoid BiocParallel crashes
  BiocParallel::register(BiocParallel::SerialParam())

  #-------------------------------
  # 1. Validate contrast levels
  #-------------------------------
  if (!"Mutation" %in% colnames(colData(dds))) {
    stop("Column 'Mutation' not found in colData(dds).")
  }

  mut_levels <- levels(dds$Mutation)

  if (!(condition1 %in% mut_levels)) {
    stop(paste("Condition1 not found in Mutation levels:", condition1))
  }
  if (!(condition2 %in% mut_levels)) {
    stop(paste("Condition2 not found in Mutation levels:", condition2))
  }

  #-------------------------------
  # 2. Run DESeq2 contrast
  #-------------------------------
  res <- DESeq2::results(
    dds,
    contrast = c("Mutation", condition1, condition2),
    independentFiltering = TRUE,
    alpha = 0.1,
    parallel = FALSE
  )

  # Remove rows with NA statistics
  res <- res[complete.cases(res$stat), ]

  #-------------------------------
  # 3. Build ranking vector
  #-------------------------------
  rnk <- setNames(res$stat, rownames(res))

  if (length(rnk) < 1000) {
    stop("Ranking vector too small (<1000 genes). Likely no signal in this contrast.")
  }

  #-------------------------------
  # 4. Load pathways
  #-------------------------------
  gmt <- fgsea::gmtPathways(gmt_path)

  #-------------------------------
  # 5. Run fgsea
  #-------------------------------
  gsea <- fgsea(
    pathways = gmt,
    stats = rnk,
    minSize = 15,
    maxSize = 500
  )

  gsea_df <- as.data.frame(gsea)

  # Flatten list columns (leadingEdge)
  list_cols <- sapply(gsea_df, is.list)
  gsea_df[list_cols] <- lapply(gsea_df[list_cols], function(x) sapply(x, paste, collapse = ";"))

  #-------------------------------
  # 6. Write outputs
  #-------------------------------
  write.csv(gsea_df, output_gsea, row.names = FALSE)

  # DEG table (filtered for significance)
  deg_df <- as.data.frame(res) %>%
    mutate(gene = rownames(res)) %>%
    filter(padj < 0.1)

  write.csv(deg_df, output_deg, row.names = FALSE)

  #-------------------------------
  # 7. Return objects invisibly
  #-------------------------------
  invisible(list(
    gsea = gsea_df,
    degs = deg_df,
    ranking = rnk
  ))
}

EnsIDReplace2 <- function(input, mapping_file = "C:/Users/rohit/OneDrive - Loyola University Chicago/Zhang Lab/Ensembl_labels_human.csv") {
  #-----------------------------
  # 1. Validate inputs
  #-----------------------------
  if (!is.matrix(input) && !is.data.frame(input)) {
    stop("Input must be a matrix or data.frame with rownames.")
  }
  if (is.null(rownames(input))) {
    stop("Input must have rownames corresponding to Ensembl IDs.")
  }
  if (!file.exists(mapping_file)) {
    stop(paste("Mapping file not found:", mapping_file))
  }

  #-----------------------------
  # 2. Load mapping file
  #-----------------------------
  gene_mapping <- read.csv(mapping_file, stringsAsFactors = FALSE)

  required_cols <- c("gene_id", "gene_name")
  if (!all(required_cols %in% colnames(gene_mapping))) {
    stop("Mapping file must contain columns: gene_id, gene_name")
  }

  #-----------------------------
  # 3. Build lookup vector
  #-----------------------------
  id_list <- setNames(gene_mapping$gene_name, gene_mapping$gene_id)

  #-----------------------------
  # 4. Vectorized name replacement
  #-----------------------------
  old_ids <- rownames(input)

  # Replace Ensembl IDs with gene names where available
  new_names <- id_list[old_ids]

  # For IDs not found in mapping, keep original
  new_names[is.na(new_names)] <- old_ids[is.na(new_names)]

  # Replace empty strings with NA
  new_names[new_names == ""] <- NA

  # Ensure syntactically valid + unique names
  new_names <- make.names(new_names, unique = TRUE)

  #-----------------------------
  # 5. Apply new rownames
  #-----------------------------
  rownames(input) <- new_names

  #-----------------------------
  # 6. Return modified object
  #-----------------------------
  return(input)
}
```

```{r rename files, eval = FALSE}
# Path to your combined metadata file
meta_file <- "C:/Users/rohit/OneDrive - Loyola University Chicago/Zhang Lab/CRK HCC/metadata.cart.2026-01-17.json"

# Path to the folder containing all the UUID subfolders
download_dir <- "C:/Users/rohit/OneDrive - Loyola University Chicago/Zhang Lab/CRK HCC/downloads/"

# Load metadata
meta <- fromJSON(meta_file)

# Build mapping: file_name → TCGA barcode
mapping <- tibble(
  file_name = meta$file_name,
  barcode   = sapply(meta$associated_entities, function(x) x$entity_submitter_id[1])
)

# Rename files inside UUID folders
for (i in seq_len(nrow(mapping))) {
  
  fname   <- mapping$file_name[i]
  barcode <- mapping$barcode[i]
  
  # Find the file recursively
  old_path <- dir(download_dir, pattern = paste0("^", fname, "$"),
                  recursive = TRUE, full.names = TRUE)
  
  if (length(old_path) == 1) {
    new_path <- file.path(dirname(old_path), paste0(barcode, ".tsv"))
    file_move(old_path, new_path)
    message("Renamed: ", fname, " → ", barcode)
  } else {
    message("Could not find file: ", fname)
  }
}


```

```{r pull files in downloads folder, eval = FALSE}
library(fs)

download_dir <- "C:/Users/rohit/OneDrive - Loyola University Chicago/Zhang Lab/CRK HCC/downloads/"

# Find all TSV files recursively
tsv_files <- dir(download_dir, pattern = "\\.tsv$", recursive = TRUE, full.names = TRUE)

# Move them to the top-level download directory
file_move(tsv_files, download_dir)
#```

#```{r merge into one counts matrix}
tsv_dir <- "C:/Users/rohit/OneDrive - Loyola University Chicago/Zhang Lab/CRK HCC/downloads/"
files <- list.files(tsv_dir, pattern = "\\.tsv$", full.names = TRUE)

read_unstranded <- function(f) {
  sample_id <- basename(f) |> str_remove("\\.tsv$")
  
  df <- read_tsv(
    f,
    comment = "#",
    col_types = cols(),
    progress = FALSE
  ) |> as_tibble()
  
  df <- df |> filter(!is.na(gene_name))
  
  df |>
    dplyr::select(gene_name, unstranded) |>
    dplyr::mutate(sample = sample_id)
}

# Read all files
long_df <- purrr::map_df(files, read_unstranded)

# Fix duplicates by summing counts
long_df_fixed <- long_df |>
  dplyr::group_by(gene_name, sample) |>
  dplyr::summarise(unstranded = sum(unstranded), .groups = "drop")

# Pivot to wide matrix
count_matrix <- long_df_fixed |>
  tidyr::pivot_wider(
    names_from = sample,
    values_from = unstranded
  ) |>
  dplyr::arrange(gene_name)

# Write to CSV
write.csv(count_matrix, "tcga_lihc_counts.csv", row.names = FALSE)
```

```{r load data}
cts <- read.csv("tcga_lihc_counts.csv", row.names = 1)
cd <- read.csv("coldata.csv")
dds <- DESeqDataSetFromMatrix(countData = cts, colData = cd, design = ~condition)
```

```{r}
dds <- estimateSizeFactors(dds)
norm <- counts(dds, normalized = TRUE) 
```

```{r vst normalize}
dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = cd,
                              design = ~ 1) # Use intercept-only for normalization

# Apply VST
vst <- vst(dds, blind = TRUE)

# Extract the normalized matrix for NTP
vst_mat <- assay(vst)
```

```{r NTP Hoshida Subtype}

gmt_file <- "hoshidasubtype.gmt" 
gs <- getGmt(gmt_file)

if (!require("GSA")) install.packages("GSA")
library(GSA)

gmt_to_ntp_template <- function(gmt_path) {
  gmt_data <- GSA.read.gmt(gmt_path)
  
  template_list <- list()
  
  for (i in 1:length(gmt_data$genesets)) {
    genes <- gmt_data$genesets[[i]]
    set_name <- gmt_data$geneset.names[i]
    
    template_list[[i]] <- data.frame(
      probe = genes,
      class = set_name,
      stringsAsFactors = FALSE
    )
  }
  
  final_template <- do.call(rbind, template_list)
  
  final_template <- final_template[final_template$probe != "" & !is.na(final_template$probe), ]
  
  return(final_template)
}

hoshida_template <- gmt_to_ntp_template("hoshidasubtype.gmt")

head(hoshida_template)
hoshida_template$class <- gsub("^HOSHIDA_LIVER_CANCER_SUBCLASS_", "", hoshida_template$class)
unique(hoshida_template$class)

# 4. Run NTP using CMScaller
# library(CMScaller)
# results <- ntp(emat = your_rna_seq_matrix, 
#                templates = hoshida_template, 
#                doPlot = TRUE)
vst_mat_centered <- ematAdjust(vst_mat)

ntp_res <- CMScaller::ntp(
  emat = as.matrix(vst_mat_centered),
  templates = hoshida_template,
  seed = 123,
  doPlot = TRUE
)
table(ntp_res$prediction)

```

```{r ntp plot}
# 1. Open the PNG device
png("Hoshida_NTP_Results.png", width = 2400, height = 2000, res = 600)

# 2. Run the function
ntp_res <- CMScaller::ntp(
  emat = as.matrix(vst_mat_centered),
  templates = hoshida_template,
  seed = 123,
  doPlot = TRUE
)

# 3. Close the device
dev.off()
```

```{r}
fdr_threshold <- 0.05

final_subtypes <- as.character(ntp_res$prediction)
final_subtypes[ntp_res$FDR > fdr_threshold] <- "Undetermined"
final_subtypes <- factor(final_subtypes)

# 3. Add to a data frame with sample IDs (assuming rownames are sample IDs)
ntp_metadata <- data.frame(
  sampleID = rownames(ntp_res),
  Hoshida_Subtype = final_subtypes,
  stringsAsFactors = FALSE
)


ntp_metadata <- ntp_metadata[match(colnames(dds), ntp_metadata$sampleID), ]

dds$Hoshida_Subtype <- as.factor(ntp_metadata$Hoshida_Subtype)

colData(dds)
```

```{r}
design(dds) <- ~ Hoshida_Subtype

# Filter out "Undetermined" samples if you want a clean comparison
# (Optional but recommended)
dds_filtered <- dds[, dds$Hoshida_Subtype != "Undetermined"]
dds_filtered$Hoshida_Subtype <- droplevels(dds_filtered$Hoshida_Subtype)

# Run DESeq
dds_filtered <- DESeq(dds_filtered)

# Apply VST
vst <- vst(dds, blind = TRUE)

# Extract the normalized matrix for NTP
vst_mat <- assay(vst)
```

```{r scatter}
plot_data <- vst_mat[c("PTK2", "CCN2"), ]

plot_data <- as.data.frame(t(vst_mat[c("PTK2", "CCN2"), ]))
plot_data$Subtype <- vst$Hoshida_Subtype

scatter <- ggplot(plot_data, aes(x = PTK2, y = CCN2, color = Subtype)) +
  geom_point(size = 3, alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE, color = "black", linetype = "dashed", size = 0.5) +
  scale_color_brewer(palette = "Set1") + # Distinct colors for S1, S2, S3
  theme_minimal() +
  labs(
    title = "FAK vs CTGF Expression",
    x = "FAK",
    y = "CTGF",
    color = "NTP Subtype"
  ) +
  theme(legend.position = "right") + 
  theme(plot.title = element_text(hjust = 0.5))
scatter

ggsave("fakctgfscatter.png", scatter, dpi = 600)
```

```{r violin}
plot_data <- as.data.frame(t(vst_mat[c("PTK2", "CCN2"), ]))
plot_data$Subtype <- vst$Hoshida_Subtype

vln <- ggplot(plot_data, aes(factor(Subtype), y = PTK2, fill = Subtype)) + 
  geom_violin() + 
  geom_jitter(width = 0.1) + 
  labs(title = "FAK Expression by Hoshida Subtype", 
       x = "Hoshida Subtype", 
       y = "FAK") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
vln

ggsave("fakvlnplot.png", vln, dpi = 600)

vln <- ggplot(plot_data, aes(factor(Subtype), y = CCN2, fill = Subtype)) + 
  geom_violin() + 
  geom_jitter(width = 0.1) + 
  labs(title = "CTGF Expression by Hoshida Subtype", 
       x = "Hoshida Subtype", 
       y = "CTGF") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
vln

ggsave("ctgfvlnplot.png", vln, dpi = 600)
```

```{r combined violin plot}
plot_data_long <- plot_data %>%
  pivot_longer(cols = c("PTK2", "CCN2"), 
               names_to = "Gene", 
               values_to = "Expression")

plot_data_long$Gene <- factor(plot_data_long$Gene, levels = c("PTK2", "CCN2"))

# 2. Create the combined plot
combined_vln <- ggplot(plot_data_long, aes(x = Subtype, y = Expression, fill = Gene)) + 
  geom_violin(position = position_dodge(0.8)) + 
  geom_jitter(position = position_jitterdodge(jitter.width = 0.1, dodge.width = 0.8)) +
  labs(title = "FAK and CTGF Expression by Subtype", 
       x = "Hoshida Subtype", 
       y = "Expression (VST Normalized)") + 
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) + 
  scale_fill_manual(values = c("PTK2" = "dodgerblue", "CCN2" = "brown1"), 
                    labels = c("PTK2" = "FAK", "CCN2" = "CTGF"))

combined_vln


# 3. Save the combined plot
ggsave("combined_vln_plot.png", combined_vln, dpi = 600)
```

```{r clinical datatable}
clinical <- read_tsv("clinical.tsv")

subtype <- colData(dds) %>%
  as.data.frame() %>%
  tibble::rownames_to_column("sample_id") %>%   # <-- different name
  mutate(
    sample_tcga = gsub("\\.", "-", sample_id),
    patient_id  = substr(sample_tcga, 1, 12)
  ) %>%
  dplyr::select(patient_id, sample_id, Hoshida_Subtype)

clinical_subset <- clinical %>%
  dplyr::select(
    cases.submitter_id,
    cases.disease_type,
    diagnoses.classification_of_tumor, 
    diagnoses.age_at_diagnosis,
    diagnoses.days_to_last_follow_up,
    demographic.vital_status
  )

merged_table <- subtype %>%
  left_join(
    clinical_subset,
    by = c("patient_id" = "cases.submitter_id")
  )

final_table <- merged_table %>%
  dplyr::select(
    patient_id,
    sample_id,
    Hoshida_Subtype,
    cases.disease_type,
    diagnoses.classification_of_tumor, 
    diagnoses.age_at_diagnosis,
    diagnoses.days_to_last_follow_up,
    demographic.vital_status
  )

final_table <- final_table %>%
  dplyr::distinct(patient_id, .keep_all = TRUE)

write.csv(final_table, "clinicaldata.csv")
rm(subtype, clinical_subset, merged_table)

```

```{r subset}
s1 <- dds[, dds$Hoshida_Subtype == "S1"]
s2 <- dds[, dds$Hoshida_Subtype == "S2"]
s3 <- dds[, dds$Hoshida_Subtype == "S3"]

s1_vst <- vst(s1, blind = TRUE)
s1_mat <- assay(s1_vst)

s2_vst <- vst(s2, blind = TRUE)
s2_mat <- assay(s2_vst)

s3_vst <- vst(s3, blind = TRUE)
s3_mat <- assay(s3_vst)
```

```{r s1 scatter}
plot_data <- as.data.frame(t(s1_mat[c("PTK2", "CCN2"), ]))
plot_data$Subtype <- s1_vst$Hoshida_Subtype

# Fit linear model
lm_fit <- lm(CCN2 ~ PTK2, data = plot_data)

# Extract stats
summary_fit <- summary(lm_fit)
r_value <- sqrt(summary_fit$r.squared)
p_value <- summary_fit$coefficients[2, 4]

# Create label text
label_text <- paste0("R = ", round(r_value, 3),
                     "\nP = ", signif(p_value, 3))

# Plot with annotation
scatter <- ggplot(plot_data, aes(x = PTK2, y = CCN2, color = Subtype)) +
  geom_point(size = 3, alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE, color = "black",
              linetype = "dashed", size = 0.5) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal() +
  labs(
    title = "FAK vs CTGF Expression",
    x = "FAK",
    y = "CTGF",
    color = "NTP Subtype"
  ) +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5)
  ) +
  annotate("text",
           x = Inf, y = -Inf,
           label = label_text,
           hjust = 1.1, vjust = -0.5,
           size = 4)

scatter

ggsave("s1fakctgfscatter.png", scatter, dpi = 600)

```

```{r s2 scatter}
plot_data <- as.data.frame(t(s2_mat[c("PTK2", "CCN2"), ]))
plot_data$Subtype <- s2_vst$Hoshida_Subtype

# Fit linear model
lm_fit <- lm(CCN2 ~ PTK2, data = plot_data)

# Extract stats
summary_fit <- summary(lm_fit)
r_value <- sqrt(summary_fit$r.squared)
p_value <- summary_fit$coefficients[2, 4]

# Create label text
label_text <- paste0("R = ", round(r_value, 3),
                     "\nP = ", signif(p_value, 3))

# Plot with annotation
scatter <- ggplot(plot_data, aes(x = PTK2, y = CCN2, color = Subtype)) +
  geom_point(size = 3, alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE, color = "black",
              linetype = "dashed", size = 0.5) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal() +
  labs(
    title = "FAK vs CTGF Expression",
    x = "FAK",
    y = "CTGF",
    color = "NTP Subtype"
  ) +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5)
  ) +
  annotate("text",
           x = Inf, y = -Inf,
           label = label_text,
           hjust = 1.1, vjust = -0.5,
           size = 4)

scatter

ggsave("s2fakctgfscatter.png", scatter, dpi = 600)
```

```{r s3 scatter}
plot_data <- as.data.frame(t(s3_mat[c("PTK2", "CCN2"), ]))
plot_data$Subtype <- s3_vst$Hoshida_Subtype

# Fit linear model
lm_fit <- lm(CCN2 ~ PTK2, data = plot_data)

# Extract stats
summary_fit <- summary(lm_fit)
r_value <- sqrt(summary_fit$r.squared)
p_value <- summary_fit$coefficients[2, 4]

# Create label text
label_text <- paste0("R = ", round(r_value, 3),
                     "\nP = ", signif(p_value, 3))

# Plot with annotation
scatter <- ggplot(plot_data, aes(x = PTK2, y = CCN2, color = Subtype)) +
  geom_point(size = 3, alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE, color = "black",
              linetype = "dashed", size = 0.5) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal() +
  labs(
    title = "FAK vs CTGF Expression",
    x = "FAK",
    y = "CTGF",
    color = "NTP Subtype"
  ) +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5)
  ) +
  annotate("text",
           x = Inf, y = -Inf,
           label = label_text,
           hjust = 1.1, vjust = -0.5,
           size = 4)

scatter

ggsave("s3fakctgfscatter.png", scatter, dpi = 600)

```